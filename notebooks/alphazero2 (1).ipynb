{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSbZGn9IWM1i",
        "outputId": "df2376f5-9fd9-4e8b-bf22-b66c84735e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
            "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
            "1.26.4\n",
            "2.2.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is not available\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available\")\n",
        "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "    \n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        device = torch.device(f'cuda:{i}')\n",
        "        print(f\"\\nCUDA Device {i}:\")\n",
        "        print(f\"  Name: {torch.cuda.get_device_name(device)}\")\n",
        "        print(f\"  Compute Capability: {torch.cuda.get_device_capability(device)}\")\n",
        "        print(f\"  Total Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.2f} GB\")\n",
        "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "09X-bvUtWM1j"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "INIT_BOARD = np.array([0, 2, 0, 0, 0, 0, -5, 0, -3, 0, 0, 0, 5,\n",
        "              -5, 0, 0, 0, 3, 0, 5, 0, 0, 0, 0, -2, 0])\n",
        "\n",
        "UNIQUE_JUMPS = [[1, 1, 1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6],\n",
        "                [2, 2, 2, 2], [2, 3], [2, 4], [2, 5], [2, 6],\n",
        "                [3, 3, 3, 3], [3, 4], [3, 5], [3, 6],\n",
        "                [4, 4, 4, 4], [4, 5], [4, 6],\n",
        "                [5, 5, 5, 5], [5, 6],\n",
        "                [6, 6, 6, 6]]\n",
        "\n",
        "def timed(function):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = function(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"{function.__name__} took {end_time - start_time} seconds to run.\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def action_to_playidx(action):\n",
        "    ''' Convert action to playidx'''\n",
        "    playidx = []\n",
        "    for i in range(4):\n",
        "        playidx.append(action % 26)\n",
        "        action = action // 26\n",
        "    return playidx\n",
        "\n",
        "def playidx_to_action(playidx):\n",
        "    '''Convert playidx to action'''\n",
        "    action = 0\n",
        "    for i in range(4):\n",
        "        action += playidx[i] * (26**i)\n",
        "    return action\n",
        "\n",
        "def roll_dice():\n",
        "    '''returns list of jumps sorted smallest to largest'''\n",
        "    die1 = random.randint(1, 6)\n",
        "    die2 = random.randint(1, 6)\n",
        "\n",
        "    if die1 == die2:\n",
        "        return [die1] * 4\n",
        "    else:\n",
        "        return sorted([die1, die2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zis422auK3Ti",
        "outputId": "93aed365-4fed-46bc-b717-2c9aff5b19af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n"
          ]
        }
      ],
      "source": [
        "INIT_BOARD = np.array(INIT_BOARD)\n",
        "print(INIT_BOARD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "_zY0C7M7WM1k"
      },
      "outputs": [],
      "source": [
        "class Backgammon:\n",
        "    def __init__(self):\n",
        "        self.idx_count = 26\n",
        "        self.action_size = 26 ** 4\n",
        "\n",
        "    def get_initial_board(self):\n",
        "        return np.array(INIT_BOARD)\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, board, player):\n",
        "        if player == -1:\n",
        "            board = np.flip(-board)\n",
        "        return board\n",
        "\n",
        "    def get_next_state(self, board, play, player):\n",
        "        for move in play:\n",
        "            self.make_move(board, move)\n",
        "        return board\n",
        "\n",
        "    def check_win(self, board):\n",
        "        return np.all(board >= 0) or np.all(board <= 0)\n",
        "\n",
        "    def get_value_and_terminated(self, board):\n",
        "        '''Always returns 1 for value'''\n",
        "        if self.check_win(board):\n",
        "            return 1, True\n",
        "        return 0, False\n",
        "\n",
        "    def get_encoded_state(self, board, jumps):\n",
        "        # [26] + jumps\n",
        "        # (7, 26) + (6)\n",
        "\n",
        "        white_cnt = np.maximum(board, 0).astype(np.float32) / 15\n",
        "        white_one = (board == 1).astype(np.float32)\n",
        "        white_tower = (board > 1).astype(np.float32)\n",
        "        black_cnt = np.maximum(-board, 0).astype(np.float32) / 15\n",
        "        black_one = (board == -1).astype(np.float32)\n",
        "        black_tower = (board < -1).astype(np.float32)\n",
        "        empty = (board == 0).astype(np.float32)  # Using small threshold for float comparison\n",
        "\n",
        "        # Stack the arrays vertically\n",
        "        encoded_board = np.vstack((white_cnt, white_one, white_tower, black_cnt, black_one, black_tower, empty))\n",
        "\n",
        "        jumps_encoded = np.zeros(4, dtype=np.float32)\n",
        "        jumps_encoded[:len(jumps)] = jumps\n",
        "        jumps_encoded = jumps_encoded/6\n",
        "\n",
        "        indicies = np.arange(26)\n",
        "        black_pip = np.sum(black_cnt * indicies) / 200\n",
        "        indicies = 25-indicies\n",
        "        white_pip = np.sum(white_cnt * indicies) / 200\n",
        "\n",
        "        features = np.concatenate([jumps_encoded, [white_pip, black_pip]]).astype(np.float32)\n",
        "\n",
        "        return encoded_board, features\n",
        "\n",
        "    def get_encoded_states_batched(self, boards, jumps):\n",
        "        # Encode boards\n",
        "        white_cnt = np.maximum(boards, 0).astype(np.float32) / 15\n",
        "        white_one = (boards == 1).astype(np.float32)\n",
        "        white_tower = (boards > 1).astype(np.float32)\n",
        "        black_cnt = np.maximum(-boards, 0).astype(np.float32) / 15\n",
        "        black_one = (boards == -1).astype(np.float32)\n",
        "        black_tower = (boards < -1).astype(np.float32)\n",
        "        empty = (boards == 0).astype(np.float32)\n",
        "\n",
        "        encoded_boards = np.stack([white_cnt, white_one, white_tower, black_cnt, black_one, black_tower, empty], axis=1)\n",
        "\n",
        "        # Encode features\n",
        "        jumps_encoded = jumps.astype(np.float32) / 6\n",
        "\n",
        "        indices = np.arange(26)\n",
        "        black_pip = np.sum(black_cnt * indices, axis=1) / 200\n",
        "        white_pip = np.sum(white_cnt * (25 - indices), axis=1) / 200\n",
        "\n",
        "        encoded_features = np.column_stack([jumps_encoded, white_pip, black_pip]).astype(np.float32)\n",
        "\n",
        "        return encoded_boards, encoded_features\n",
        "\n",
        "    def get_valid_plays(self, board, jumps, player):\n",
        "        if len(jumps) == 4:\n",
        "            return self._generate_plays_quads(board, jumps)\n",
        "        return self._generate_plays(board, jumps)\n",
        "\n",
        "    def plays_to_actions(self, plays):\n",
        "        actions = np.zeros(self.action_size)\n",
        "        for play in plays:\n",
        "            play_idx = []\n",
        "            for move in sorted(play, key=lambda move: (move[1]-move[0])):\n",
        "                play_idx.append(move[0])\n",
        "            while len(play_idx) < 4:\n",
        "                play_idx.append(25)\n",
        "\n",
        "            action_idx = playidx_to_action(play_idx)\n",
        "            actions[action_idx] = 1\n",
        "        return actions\n",
        "\n",
        "    def play_to_action(self, play):\n",
        "        play = sorted(play, key=lambda move: (move[1]-move[0]))\n",
        "        play_idx = []\n",
        "        for move in play:\n",
        "            play_idx.append(move[0])\n",
        "        while len(play_idx) < 4:\n",
        "            play_idx.append(25)\n",
        "        return playidx_to_action(play_idx)\n",
        "\n",
        "\n",
        "    def is_valid_move(self, board, jumps, move):\n",
        "        # print(board)\n",
        "        start, end = move[0], move[1]\n",
        "\n",
        "        jump = abs(end - start)\n",
        "        if jump not in jumps:\n",
        "            return False\n",
        "\n",
        "        # Check if start exists\n",
        "        # print(board)\n",
        "        # print(move)\n",
        "        if board[start] <= 0:\n",
        "            return False\n",
        "\n",
        "        # Check if move is in right direction\n",
        "        if end <= start:\n",
        "            return False\n",
        "\n",
        "        # Check if jailed\n",
        "        if board[0] > 0:\n",
        "            if start != 0:\n",
        "                return False\n",
        "\n",
        "        # Check if trying to bear off\n",
        "        if end >= 25:\n",
        "            if np.all(board[0:19] <= 0):\n",
        "                if end == 25:\n",
        "                    return True\n",
        "                elif np.all(board[19:start] <= 0):\n",
        "                    return True\n",
        "                return False\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        # Check if end is blocked\n",
        "        if board[end] < -1:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _generate_plays(self, board, jumps):\n",
        "        # print(\"Generating plays\")\n",
        "        board = board\n",
        "        jumps = jumps\n",
        "\n",
        "        def get_movable_pieces(board):\n",
        "            if board[0] > 0:\n",
        "                return [0]\n",
        "            moveable_pieces = []\n",
        "            for i in range(len(board)):\n",
        "                if board[i] > 0:\n",
        "                    moveable_pieces.append(i)\n",
        "            return moveable_pieces\n",
        "\n",
        "        res = []\n",
        "\n",
        "        play = []\n",
        "\n",
        "        def dfs(board, jumps):\n",
        "            #print(\"called dfs\")\n",
        "            movable_pieces = get_movable_pieces(board)\n",
        "            # print(f\"movable_pieces: {get_movable_pieces(board)} with jumps {jumps}\")\n",
        "            if movable_pieces == [] or jumps == []:\n",
        "                res.append(copy.deepcopy(play))\n",
        "                return\n",
        "\n",
        "\n",
        "\n",
        "            for piece in movable_pieces:\n",
        "                for j in range(len(jumps)):\n",
        "                    move = (piece, piece+jumps[j])  # make negative for black\n",
        "                    # print(board, movable_pieces, move)\n",
        "                    # print(\"hi\")\n",
        "                    if self.is_valid_move(board, jumps, move) == False:\n",
        "                        # print(\"Invalid move\")\n",
        "                        res.append(copy.deepcopy(play))\n",
        "                        continue\n",
        "\n",
        "                    #print(f\"board: {board}, jumps={jumps}\")\n",
        "                    #print(f\"move: {move}\")\n",
        "                    tmp_board = board.copy()\n",
        "                    tmp_board = self.make_move(tmp_board, move)\n",
        "\n",
        "                    tmp_jump = copy.copy(jumps)\n",
        "                    tmp_jump.pop(j)\n",
        "                    #print(f\"tmp_board: {tmp_board}, tmp_jump={tmp_jump}\")\n",
        "                    #print()\n",
        "\n",
        "                    play.append(move)\n",
        "\n",
        "                    dfs(tmp_board, tmp_jump)\n",
        "                    play.pop()\n",
        "\n",
        "        def remove_duplicate_plays(res):\n",
        "            res = [tuple(play) for play in res]\n",
        "            res = set(res)\n",
        "            res = list(res)\n",
        "            res = [list(play) for play in res]\n",
        "            return res\n",
        "\n",
        "        def sort_plays(res):\n",
        "            for i in range(len(res)):\n",
        "                res[i] = sorted(res[i], key=lambda x: (x[0], x[1]))\n",
        "            return res\n",
        "\n",
        "        dfs(board, jumps)\n",
        "        # print(f\"{len(res)} plays generated by dfs\")\n",
        "        # print(res)\n",
        "        if not res:\n",
        "            return []\n",
        "        res = sort_plays(res)\n",
        "        res = remove_duplicate_plays(res)\n",
        "        # print(res)\n",
        "        # res.sort(key=lambda x: [x[0][0], x[1][0], x[0][1]])\n",
        "        max_length_play = max(len(play) for play in res)\n",
        "        res = [play for play in res if len(play) == max_length_play]\n",
        "\n",
        "        return res\n",
        "\n",
        "    def _generate_plays_quads(self, board, jumps):\n",
        "\n",
        "        def get_movable_pieces(board):\n",
        "            if board[0] > 0:\n",
        "                return [0]\n",
        "            moveable_pieces = []\n",
        "            for i in range(len(board)):\n",
        "                if board[i] > 0:\n",
        "                    moveable_pieces.append(i)\n",
        "            return moveable_pieces\n",
        "\n",
        "        res = []\n",
        "        play = []\n",
        "\n",
        "        def dfs(board, jumps):\n",
        "            movable_pieces = get_movable_pieces(board)\n",
        "            if movable_pieces == [] or jumps == []:\n",
        "                res.append(copy.deepcopy(play))\n",
        "                return\n",
        "\n",
        "            for piece in movable_pieces:\n",
        "                move = (piece, piece+jumps[0])\n",
        "\n",
        "                if self.is_valid_move(board, jumps, move) == False:\n",
        "                    res.append(copy.deepcopy(play))\n",
        "                    continue\n",
        "\n",
        "\n",
        "                #print(f\"board: {board}, jumps={jumps}\")\n",
        "                #print(f\"move: {move}\")\n",
        "                tmp_board = board.copy()\n",
        "                tmp_board = self.make_move(tmp_board, move)\n",
        "                tmp_jump = copy.copy(jumps)\n",
        "                tmp_jump.pop()\n",
        "                #print(f\"tmp_board: {tmp_board}, tmp_jump={tmp_jump}\")\n",
        "                #print()\n",
        "                play.append(move)\n",
        "\n",
        "                dfs(tmp_board, tmp_jump)\n",
        "                play.pop()\n",
        "        dfs(board, jumps)\n",
        "\n",
        "        def sort_plays(res):\n",
        "            for i in range(len(res)):\n",
        "                res[i] = sorted(res[i], key=lambda x: (x[0]))\n",
        "            return res\n",
        "        sorted_res = sort_plays(res)\n",
        "\n",
        "        def remove_duplicate_plays(res):\n",
        "            res = [tuple(play) for play in res]\n",
        "            res = set(res)\n",
        "            res = list(res)\n",
        "            res = [list(play) for play in res]\n",
        "            return res\n",
        "        processed_res = remove_duplicate_plays(sorted_res)\n",
        "\n",
        "        if not processed_res:\n",
        "            return []\n",
        "\n",
        "        max_length_play = max(len(play) for play in processed_res)\n",
        "        longest_plays = [play for play in processed_res if len(play) == max_length_play]\n",
        "\n",
        "        return longest_plays\n",
        "\n",
        "    def make_move(self, board, move) -> None:\n",
        "        '''Apply move on board'''\n",
        "        start, end = move\n",
        "\n",
        "        if board[start] == 0:\n",
        "            raise ValueError(f\"Invalid move {move}: No piece to move at start position. Board: \\n{self.draw(board)}\")\n",
        "        board[start] -= 1\n",
        "        # Handle bearoff\n",
        "        if end >= 25:\n",
        "            return board\n",
        "        # Handle hitting opponent checker\n",
        "        if board[end] == -1:\n",
        "            board[end] = 1\n",
        "            board[25] -= 1\n",
        "        elif board[end] < -1:\n",
        "            raise ValueError(f\"Invalid move {move}: End position has more than -1 checker. Board: \\n{self.draw(board)}\")\n",
        "        # Handle regular move\n",
        "        else:\n",
        "            board[end] += 1\n",
        "        return board\n",
        "\n",
        "    def draw(self, board) -> str:\n",
        "        '''String representation of the board'''\n",
        "        def transform(i):\n",
        "            x = str(i)\n",
        "            if x[0] != \"-\":\n",
        "                x = \" \" + x\n",
        "            if len(x) < 3:\n",
        "                x += \" \"\n",
        "            return x\n",
        "\n",
        "        # top index numbers for the board\n",
        "        top_idx = \"  \" + \" \".join(f\"{transform(i)}\" for i in range(12, 0, -1)) + \"   \" + transform(0)\n",
        "\n",
        "        # bottom index numbers for the board\n",
        "        bot_idx = \"  \" + \" \".join(f\"{transform(i)}\" for i in range(13, 25)) + \"   \" + transform(25)\n",
        "\n",
        "        # ===== boarder for top and bottom\n",
        "        boarder = \"=\"*57\n",
        "\n",
        "        # top row of the board from board\n",
        "        top = \"||\" + \\\n",
        "            \" \".join(f\"{transform(board[i])}\" for i in range(12, 6, -1)) + \"|\" + \\\n",
        "            \" \".join(f\"{transform(board[i])}\" for i in range(6, 0, -1)) + \"|| \" + \\\n",
        "            str(transform(board[0]))\n",
        "\n",
        "        # bottom row of the board from board\n",
        "        bot = \"||\" + \\\n",
        "            \" \".join(f\"{transform(board[i])}\" for i in range(13, 19)) + \"|\" + \\\n",
        "            \" \".join(f\"{transform(board[i])}\" for i in range(19, 25)) + \"|| \" + \\\n",
        "            str(transform(board[25]))\n",
        "\n",
        "        # x combines all the strings together to make the board\n",
        "        x = top_idx + \"\\n\" + boarder + \"\\n\" + top + \\\n",
        "            \"\\n\\n\\n\" + bot + \"\\n\" + boarder + \"\\n\" + bot_idx\n",
        "\n",
        "        # print(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "htkacUPGWM1l"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, game, args, board, jumps, parent=None, action_taken=None, play_taken=None, prior=0, visit_count=0, level=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.board = board\n",
        "        self.jumps = jumps\n",
        "        self.parent = parent\n",
        "        self.play_taken = play_taken\n",
        "        self.action_taken = action_taken\n",
        "\n",
        "        self.prior = prior\n",
        "        self.children = []\n",
        "\n",
        "        self.visit_count = visit_count\n",
        "        self.value_sum = 0\n",
        "        self.state_value = None\n",
        "\n",
        "        self.level = level\n",
        "\n",
        "        self.search_weight = 1\n",
        "        if self.jumps and len(self.jumps) == 2:\n",
        "            self.search_weight = 2\n",
        "\n",
        "    def __str__(self):\n",
        "        board_repr = self.game.draw(board=self.board)\n",
        "        board_repr = '\\n'.join([\" \"*2*self.level + line for line in board_repr.splitlines()])\n",
        "        return \\\n",
        "f\"\"\"\n",
        "{\" \"*2*self.level}{\"-\"*60}\n",
        "{\" \"*2*self.level}Level: {self.level}, N: {self.visit_count}, val: {self.value_sum:.3f}, prior: {self.prior:.3f}, uct:{self.parent.get_ucb(self) if self.parent else None}, weight: {self.search_weight}, num_children: {len(self.children)}\n",
        "{board_repr}\n",
        "{\" \"*2*self.level}jumps={self.jumps}, state_value={self.state_value}, action_taken={self.action_taken}\n",
        "{\"  \"*2*self.level}board = {self.board}\n",
        "{\" \"*2*self.level}{\"-\"*60}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        if self.jumps == []:\n",
        "            return self.find_random_child_weighted()\n",
        "        else:\n",
        "            best_child = None\n",
        "            best_ucb = -np.inf\n",
        "\n",
        "            for child in self.children:\n",
        "                ucb = self.get_ucb(child)\n",
        "                if ucb > best_ucb:\n",
        "                    best_child = child\n",
        "                    best_ucb = ucb\n",
        "\n",
        "            return best_child\n",
        "\n",
        "    def get_ucb(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = float(\"inf\")\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
        "\n",
        "    def find_random_child_weighted(self):\n",
        "        if not self.children:\n",
        "            raise RuntimeError(\n",
        "                f\"find random child weighted called on leaf node {self.node}\")\n",
        "        weights = [child.search_weight for child in self.children]\n",
        "        selected_child = random.choices(self.children, weights=weights, k=1)[0]\n",
        "        return selected_child\n",
        "\n",
        "    def expand(self, policy, plays):\n",
        "        # plays = self.game.get_valid_plays(self.board, self.jumps, 1)\n",
        "        if len(self.children) > 0:\n",
        "            # print(f\"expand():skip already expanded node\")\n",
        "            return\n",
        "        for play in plays:\n",
        "            child_action_taken = self.game.play_to_action(play)\n",
        "            child_board = self.board.copy()\n",
        "            child_board = self.game.get_next_state(child_board, play, 1)\n",
        "            child_board = self.game.change_perspective(child_board, player=-1)\n",
        "            child_prior = float(policy[child_action_taken])\n",
        "\n",
        "\n",
        "            child = Node(self.game, self.args, board=child_board, jumps=[], parent=self, action_taken=child_action_taken, prior=child_prior, visit_count=0, level=self.level+1)\n",
        "            self.children.append(child)\n",
        "\n",
        "            if play == [[]]:\n",
        "                print(f\"created {len(self.children)} children for play {play}\")\n",
        "\n",
        "            for possible_jump in UNIQUE_JUMPS:\n",
        "                child_child = Node(self.game, self.args, board=child_board, jumps=possible_jump, parent=child, action_taken=child_action_taken, prior=1, visit_count=0, level=self.level+2)\n",
        "                child.children.append(child_child)\n",
        "\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "        if self.jumps == []:\n",
        "            value = self.game.get_opponent_value(value)\n",
        "        if self.parent is not None:\n",
        "            self.parent.backpropagate(value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "tuWYNeIKWM1m"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks, num_hidden, num_features, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv1d(7, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        # Policy head\n",
        "        self.policyConv = nn.Conv1d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.policyBN = nn.BatchNorm1d(num_hidden)\n",
        "        self.policyFlatten = nn.Flatten()\n",
        "        self.policyLinear = nn.Sequential(\n",
        "            nn.Linear(num_hidden * game.idx_count + num_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, game.action_size)\n",
        "        )\n",
        "\n",
        "        # Value head\n",
        "        self.valueConv = nn.Conv1d(num_hidden, 2, kernel_size=3, padding=1)\n",
        "        self.valueBN = nn.BatchNorm1d(2)\n",
        "        self.valueFlatten = nn.Flatten()\n",
        "        self.valueLinear = nn.Sequential(\n",
        "            nn.Linear(2 * game.idx_count + num_features, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.to(device)\n",
        "    #@timed\n",
        "    def forward(self, x, features):\n",
        "        x = self.startBlock(x)\n",
        "        for resBlock in self.backBone:\n",
        "            x = resBlock(x)\n",
        "\n",
        "        # Policy head\n",
        "        policy = self.policyConv(x)\n",
        "        policy = self.policyBN(policy)\n",
        "        policy = F.relu(policy)\n",
        "        policy = self.policyFlatten(policy)\n",
        "        policy = torch.cat([policy, features], dim=1)\n",
        "        policy = self.policyLinear(policy)\n",
        "\n",
        "        # Value head\n",
        "        value = self.valueConv(x)\n",
        "        value = self.valueBN(value)\n",
        "        value = F.relu(value)\n",
        "        value = self.valueFlatten(value)\n",
        "        value = torch.cat([value, features], dim=1)\n",
        "        value = self.valueLinear(value)\n",
        "\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(num_hidden)\n",
        "        self.conv2 = nn.Conv1d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "7pGmzR4tWM1m"
      },
      "outputs": [],
      "source": [
        "class MCTS:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, board, jumps):\n",
        "        root = Node(self.game, self.args, board, jumps, visit_count=1)\n",
        "        device = self.model.device\n",
        "\n",
        "        enc_board, enc_features = self.game.get_encoded_state(root.board, root.jumps)\n",
        "        policy, value = self.model(torch.tensor(enc_board, device=device).unsqueeze(0), torch.tensor(enc_features, device=device).unsqueeze(0))\n",
        "\n",
        "        value = float(value.item())\n",
        "\n",
        "\n",
        "        policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
        "\n",
        "        valid_plays = self.game.get_valid_plays(root.board, root.jumps, 1)\n",
        "        valid_actions = self.game.plays_to_actions(valid_plays)\n",
        "        policy *= valid_actions\n",
        "        policy /= np.sum(policy)\n",
        "\n",
        "\n",
        "        root.state_value = value\n",
        "        root.expand(policy, valid_plays)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            # print(search)\n",
        "            node = root\n",
        "\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(node.board)\n",
        "            value = self.game.get_opponent_value(value)\n",
        "\n",
        "            if not is_terminal:\n",
        "                enc_board, enc_features = self.game.get_encoded_state(node.board, node.jumps)\n",
        "                policy, value = self.model(torch.tensor(enc_board, device=device).unsqueeze(0), torch.tensor(enc_features, device=device).unsqueeze(0))\n",
        "                value = float(value.item())\n",
        "                node.state_value = value\n",
        "\n",
        "                policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "                valid_plays = self.game.get_valid_plays(node.board, node.jumps, 1)\n",
        "                valid_actions = self.game.plays_to_actions(valid_plays)\n",
        "                policy *= valid_actions\n",
        "                policy /= np.sum(policy)\n",
        "\n",
        "                node.expand(policy, valid_plays)\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "\n",
        "        action_probs = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            action_probs[child.action_taken] = child.visit_count\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs, root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "xhAnPY_KWM1m"
      },
      "outputs": [],
      "source": [
        "TEST_BOARD = np.array([0, 2, 0, 0, 0, 0, -3, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, -2, 0])\n",
        "\n",
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTS(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        # board = self.game.get_initial_board()\n",
        "        # jumps = roll_dice()\n",
        "        board = INIT_BOARD\n",
        "        jumps = [1,3]\n",
        "\n",
        "        while True:\n",
        "            # neutral_board = self.game.change_perspective(board, player)\n",
        "            action_probs, root = self.mcts.search(board, jumps)\n",
        "\n",
        "\n",
        "            memory.append((board, jumps, action_probs, player))\n",
        "\n",
        "            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "            temperature_action_probs /= np.sum(temperature_action_probs)\n",
        "            # Add this check\n",
        "            if np.isnan(temperature_action_probs).any():\n",
        "                raise ValueError(f\"AZ.selfPlay(): NaN detected in temperature_action_probs: {temperature_action_probs}\")\n",
        "\n",
        "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "            # print(\"+\"*60)\n",
        "            # print(f\"Finished search for player {player}:\")\n",
        "            # print(root)\n",
        "            # print(f\"action taken: {action}, {action_to_playidx(action)}\")\n",
        "            # print(\"+\"*60)\n",
        "            # print()\n",
        "\n",
        "            # Make move based on policy\n",
        "            #state = self.game.get_next_state(state, action, player)\n",
        "            child = None\n",
        "            for child in root.children:\n",
        "                if child.action_taken == action:\n",
        "                    child = child\n",
        "                    break\n",
        "            if child is None:\n",
        "                raise ValueError(f\"Child node with action {action} not found\")\n",
        "            child = child.find_random_child_weighted()\n",
        "\n",
        "            board = child.board\n",
        "            # board = self.game.change_perspective(board, -1)\n",
        "            jumps = child.jumps\n",
        "\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(board)\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_neutral_board, hist_jumps, hist_action_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    encoded_board, encoded_features = self.game.get_encoded_state(hist_neutral_board, hist_jumps)\n",
        "                    returnMemory.append((\n",
        "                        encoded_board,\n",
        "                        encoded_features,\n",
        "                        hist_action_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                # print(\"Game over. Value: \", value)\n",
        "                # print(f\"state[-4] Value: {returnMemory[-4][3]}\")\n",
        "                # print(f\"state[-3] Value: {returnMemory[-3][3]}\")\n",
        "                # print(f\"state[-2] Value: {returnMemory[-2][3]}\")\n",
        "                # print(f\"state[-1] Value: {returnMemory[-1][3]}\")\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            if len(sample) == 0:\n",
        "                continue\n",
        "            board, jumps, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            board, jumps, policy_targets, value_targets = np.array(board), np.array(jumps), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            board = torch.tensor(board, dtype=torch.float32, device=self.model.device)\n",
        "            jumps = torch.tensor(jumps, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(board, jumps)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            # torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
        "            # torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")\n",
        "        torch.save(self.model.state_dict(), f\"model_final.pt\")\n",
        "        torch.save(self.optimizer.state_dict(), f\"optimizer_final.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "b9Sz-FYy7md5"
      },
      "outputs": [],
      "source": [
        "class MCTSParallel:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, spGames):\n",
        "\n",
        "        boards, padded_jumps = [], []\n",
        "        for spg in spGames:\n",
        "            boards.append(spg.board)\n",
        "            if len(spg.jumps) < 4:\n",
        "                padded_jumps.append(spg.jumps + [0,0])\n",
        "            else:\n",
        "                padded_jumps.append(spg.jumps)\n",
        "        boards = np.array(boards, dtype=np.float32)\n",
        "        padded_jumps = np.array(padded_jumps, dtype=np.float32)\n",
        "\n",
        "        enc_boards, enc_features = self.game.get_encoded_states_batched(boards, padded_jumps)\n",
        "        policy, value = self.model(\n",
        "            torch.tensor(enc_boards, device=self.model.device),\n",
        "            torch.tensor(enc_features, device=self.model.device)\n",
        "        )\n",
        "\n",
        "        policy = torch.softmax(policy, axis=1).detach().cpu().numpy()\n",
        "        value = value.detach().cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
        "\n",
        "        # print(f\"Top of search, policy shape: {policy.shape}, boards shape: {boards.shape}, jumps shape: {jumps.shape}\")\n",
        "\n",
        "\n",
        "        for i, spg in enumerate(spGames):\n",
        "            # if i == 0:\n",
        "            #     print(f\"In enumerate spGames, policy[i] shape: {policy[i].shape}, boards[i] shape: {boards[i].shape}, jumps[i] shape: {jumps[i].shape}\")\n",
        "            spg_board, spg_jumps = spg.board, spg.jumps\n",
        "            spg_policy, spg_value = policy[i], float(value[i][0])\n",
        "            valid_plays = self.game.get_valid_plays(spg_board, spg_jumps, 1)\n",
        "            valid_actions = self.game.plays_to_actions(valid_plays)\n",
        "            spg_policy *= valid_actions\n",
        "            spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "            if spg.root is None:\n",
        "                spg.root = Node(self.game, self.args, spg_board, spg_jumps, visit_count=1)\n",
        "            spg.root.expand(spg_policy, valid_plays)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            for spg in spGames:\n",
        "                spg.node = None\n",
        "                node = spg.root\n",
        "                while node.is_fully_expanded():\n",
        "                    node = node.select()\n",
        "                value, is_terminal = self.game.get_value_and_terminated(node.board)\n",
        "                value = self.game.get_opponent_value(value)\n",
        "                if is_terminal:\n",
        "                    node.backpropagate(value)\n",
        "                else:\n",
        "                    spg.node = node\n",
        "\n",
        "\n",
        "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
        "\n",
        "            if len(expandable_spGames) > 0:\n",
        "                boards = []\n",
        "                jumps = []\n",
        "                for mappingIdx in expandable_spGames:\n",
        "                    boards.append(spGames[mappingIdx].node.board)\n",
        "                    if len(spGames[mappingIdx].node.jumps) < 4:\n",
        "                        jumps.append(spGames[mappingIdx].node.jumps + [0,0])\n",
        "                    else:\n",
        "                        jumps.append(spGames[mappingIdx].node.jumps)\n",
        "                boards = np.array(boards, dtype=np.float32)\n",
        "                jumps = np.array(jumps, dtype=np.float32)\n",
        "\n",
        "                enc_boards, enc_features = self.game.get_encoded_states_batched(boards, jumps)\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(enc_boards, device=self.model.device),\n",
        "                    torch.tensor(enc_features, device=self.model.device)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).detach().cpu().numpy()\n",
        "                value = value.detach().cpu().numpy()\n",
        "\n",
        "            for i, mappingIdx in enumerate(expandable_spGames):\n",
        "                node = spGames[mappingIdx].node\n",
        "                spg_policy, spg_value = policy[i], float(value[i][0])\n",
        "                node.state_value = spg_value\n",
        "\n",
        "                valid_plays = self.game.get_valid_plays(node.board, node.jumps, 1)\n",
        "                valid_actions = self.game.plays_to_actions(valid_plays)\n",
        "                spg_policy *= valid_actions\n",
        "                spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "                node.expand(spg_policy, valid_plays)\n",
        "                node.backpropagate(spg_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "vaZufZ6-7lW8"
      },
      "outputs": [],
      "source": [
        "TEST_BOARD = np.array([0, 2, 0, 0, 0, 0, -3, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, -2, 0])\n",
        "\n",
        "\n",
        "class AlphaZeroParallel:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTSParallel(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        return_memory = []\n",
        "        player = 1\n",
        "        spGames = [SPG(self.game) for spg in range(self.args['num_parallel_games'])]\n",
        "\n",
        "        P1_wins = 0\n",
        "        P2_wins = 0\n",
        "\n",
        "        while len(spGames) > 0:\n",
        "            start_time = time.time()\n",
        "\n",
        "            self.mcts.search(spGames)\n",
        "\n",
        "            for i in range(len(spGames))[::-1]:\n",
        "                spg = spGames[i]\n",
        "\n",
        "                action_probs = np.zeros(self.game.action_size)\n",
        "                for child in spg.root.children:\n",
        "                    action_probs[child.action_taken] = child.visit_count\n",
        "                if np.sum(action_probs) == 0:\n",
        "                    print(f\"    AZF.selfPlay(): Sum of spGames action probs is 0, action_probs{action_probs}\")\n",
        "\n",
        "\n",
        "                action_probs /= np.sum(action_probs)\n",
        "\n",
        "                spg.memory.append((spg.root.board, spg.root.jumps, action_probs, player))\n",
        "\n",
        "                temperature_action_probs = action_probs  ** (1 / self.args['temperature'])\n",
        "                temperature_action_probs /= np.sum(temperature_action_probs)\n",
        "                # Add this check\n",
        "                if np.isnan(temperature_action_probs).any():\n",
        "                    print(spg.root)\n",
        "                    for child in spg.root.children:\n",
        "                        print(child)\n",
        "                    raise ValueError(f\"AZF.selfPlay(): NaN detected in temperature_action_probs: {temperature_action_probs}, action_probs{action_probs}\")\n",
        "\n",
        "                action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "\n",
        "                chosen_child = None\n",
        "                for child in spg.root.children:\n",
        "                    if child.action_taken == action:\n",
        "                        chosen_child = child\n",
        "                        break\n",
        "                if chosen_child is None:\n",
        "                    raise ValueError(f\"AZF.selfPlay(): Chosen child node with action {action} not found\")\n",
        "\n",
        "                spg.root = chosen_child.find_random_child_weighted()\n",
        "                spg.root.parent = None\n",
        "                spg.board = spg.root.board\n",
        "                spg.jumps = spg.root.jumps\n",
        "\n",
        "                value, is_terminal = self.game.get_value_and_terminated(spg.board)\n",
        "                if is_terminal:\n",
        "                    if player == 1:\n",
        "                        P1_wins += 1\n",
        "                    else:\n",
        "                        P2_wins += 1\n",
        "                    # print(f\"AZ.selfPlay: Terminal State. Add  {len(spg.memory)} rows of data to return_memory.\")\n",
        "                    for hist_neutral_board, hist_jumps, hist_action_probs, hist_player in spg.memory:\n",
        "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                        encoded_board, encoded_features = self.game.get_encoded_state(hist_neutral_board, hist_jumps)\n",
        "                        return_memory.append((\n",
        "                            encoded_board,\n",
        "                            encoded_features,\n",
        "                            hist_action_probs,\n",
        "                            hist_outcome\n",
        "                        ))\n",
        "                    # print(f\"\\nAZF.selfPlay(): SFgame ended with {len(spg.memory)} states:\")\n",
        "                    # print(f\"memory[0]: {spg.memory[0][0]}, Player= {spg.memory[0][3]}, V= {return_memory[0][3]}\")\n",
        "                    # print(f\"memory[1]: {spg.memory[1][0]}, Player= {spg.memory[1][3]}, V= {return_memory[1][3]}\")\n",
        "                    # print(f\"memory[2]: {spg.memory[2][0]}, Player= {spg.memory[2][3]}, V= {return_memory[2][3]}\")\n",
        "                    # print(f\"memory[-3]: {spg.memory[-3][0]}, jumps={spg.memory[-3][1]}, Player= {spg.memory[-3][3]}, V= {return_memory[-3][3]}\")\n",
        "                    # print(f\"memory[-2]: {spg.memory[-2][0]}, jumps={spg.memory[-2][1]}, Player= {spg.memory[-2][3]}, V= {return_memory[-2][3]}\")\n",
        "                    # print(f\"memory[-1]: {spg.memory[-1][0]}, jumps={spg.memory[-1][1]}, Player= {spg.memory[-1][3]}, V= {return_memory[-1][3]}\")\n",
        "                    # print(f\"\")\n",
        "                    del spGames[i]\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "            end_time = time.time()\n",
        "            iteration_time = end_time - start_time\n",
        "            print(f\"AZF.selfPlay(): SP iteration time: {iteration_time:.4f} seconds for {len(spGames)} games with {self.args['num_searches']} num_searches\")\n",
        "        print(f\"AFZ.selfPlay(): P1 wins {P1_wins} P-1 wins {P2_wins}\")\n",
        "        return return_memory\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        total_policy_loss = 0\n",
        "        total_value_loss = 0\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            if len(sample) == 0:\n",
        "                continue\n",
        "            board, jumps, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            board, jumps, policy_targets, value_targets = np.array(board), np.array(jumps), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            board = torch.tensor(board, dtype=torch.float32, device=self.model.device)\n",
        "            jumps = torch.tensor(jumps, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(board, jumps)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            total_policy_loss += policy_loss.item()\n",
        "            total_value_loss += value_loss.item()\n",
        "        total_value_loss /= len(memory)\n",
        "        total_policy_loss /= len(memory)\n",
        "        print(f\"AZ.Train(): Total policy loss: {total_policy_loss}, Total value loss: {total_value_loss}\")\n",
        "        \n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            print(f\"AZ.Learn(): Total memory length: {len(memory)}\")\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_init_{iteration}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_init_{iteration}.pt\")\n",
        "        torch.save(self.model.state_dict(), f\"model_final.pt\")\n",
        "        torch.save(self.optimizer.state_dict(), f\"optimizer_final.pt\")\n",
        "\n",
        "class SPG:\n",
        "    def __init__(self, game):\n",
        "        self.board = INIT_BOARD\n",
        "        self.jumps = [1, 3]\n",
        "        self.memory = []\n",
        "        self.root = None\n",
        "        self.node = None\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnRiEoC79uc_",
        "outputId": "f3c1eb7b-212a-4526-d20c-c121b155cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   9039 MiB |  14433 MiB |    956 GiB |    948 GiB |\n",
            "|       from large pool |   9028 MiB |  14416 MiB |    585 GiB |    576 GiB |\n",
            "|       from small pool |     10 MiB |     82 MiB |    371 GiB |    371 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   9039 MiB |  14433 MiB |    956 GiB |    948 GiB |\n",
            "|       from large pool |   9028 MiB |  14416 MiB |    585 GiB |    576 GiB |\n",
            "|       from small pool |     10 MiB |     82 MiB |    371 GiB |    371 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   9033 MiB |  14424 MiB |    953 GiB |    945 GiB |\n",
            "|       from large pool |   9022 MiB |  14407 MiB |    583 GiB |    574 GiB |\n",
            "|       from small pool |     10 MiB |     82 MiB |    370 GiB |    370 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  15602 MiB |  15602 MiB |  15602 MiB |      0 B   |\n",
            "|       from large pool |  15504 MiB |  15504 MiB |  15504 MiB |      0 B   |\n",
            "|       from small pool |     98 MiB |     98 MiB |     98 MiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 232330 KiB | 457575 KiB |   1502 GiB |   1502 GiB |\n",
            "|       from large pool | 226664 KiB | 444305 KiB |   1131 GiB |   1130 GiB |\n",
            "|       from small pool |   5666 KiB |  21890 KiB |    371 GiB |    371 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |    1244    |    2703    |    6209 K  |    6208 K  |\n",
            "|       from large pool |      27    |      44    |      61 K  |      61 K  |\n",
            "|       from small pool |    1217    |    2660    |    6148 K  |    6146 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |    1244    |    2703    |    6209 K  |    6208 K  |\n",
            "|       from large pool |      27    |      44    |      61 K  |      61 K  |\n",
            "|       from small pool |    1217    |    2660    |    6148 K  |    6146 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      66    |      66    |      66    |       0    |\n",
            "|       from large pool |      17    |      17    |      17    |       0    |\n",
            "|       from small pool |      49    |      49    |      49    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      13    |      61    |    2075 K  |    2075 K  |\n",
            "|       from large pool |       4    |      10    |      20 K  |      20 K  |\n",
            "|       from small pool |       9    |      57    |    2054 K  |    2054 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Set seeds\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# If you're using CUDA (GPU), also set the CUDA seed\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "print(torch.cuda.memory_summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji-Brd499jU7"
      },
      "source": [
        "#AlphaParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "tKTMi7Or9IB1"
      },
      "outputs": [],
      "source": [
        "bg = Backgammon()\n",
        "model = ResNet(game=bg, num_resBlocks=20, num_hidden=64, num_features=6, device=device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "toESIic536FP"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), f\"model_init.pt\")\n",
        "torch.save(optimizer.state_dict(), f\"optimizer_init.pt\")\n",
        "\n",
        "# model = ResNet(game=bg, num_resBlocks=20, num_hidden=64, num_features=6, device=device)\n",
        "# model.load_state_dict(torch.load(\"model_final.pt\", map_location=device))\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijJEkbMtWM1m",
        "outputId": "634c16d5-e19a-4b12-a0cf-1d4fedec7c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Level: 0, N: 201, val: 5.028, prior: 0.000, uct:None, weight: 2, num_children: 19\n",
            "   12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "=========================================================\n",
            "|| 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "\n",
            "\n",
            "||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "=========================================================\n",
            "   13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "jumps=[1, 3], state_value=-0.06579335778951645, action_taken=None\n",
            "------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.04994314288099607\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -0.300, prior: 0.031, uct:0.6485708339475742, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456761\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.08832397205489022\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.618, prior: 0.029, uct:0.6461254808468638, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2  -1 |-4   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456811\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.06473447435668536\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.453, prior: 0.030, uct:0.6380742726673874, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0  -1   0 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456327\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.0530270499487718\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -0.318, prior: 0.030, uct:0.6469816885529953, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456743\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.01713670268654823\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 5, val: -0.086, prior: 0.029, uct:0.6443488229297712, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -3   0 |-4  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456631\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.03639790774146213\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 79, val: 2.875, prior: 0.469, uct:0.6479780413894389, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -1  -1 |-5  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456759\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.0504355462534087\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.353, prior: 0.030, uct:0.6307051962449172, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456785\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.07565809679882866\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.530, prior: 0.029, uct:0.6416996244904387, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456330\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.06279959636075157\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.440, prior: 0.029, uct:0.6337748300136994, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456345\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.069219351879188\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.485, prior: 0.030, uct:0.6411746967016331, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456839\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.10030630743131042\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 8, val: -0.802, prior: 0.029, uct:0.6424293529063188, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456613\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.06627787862505231\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.464, prior: 0.030, uct:0.6393251905054015, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -2  -1 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456629\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.05506639555096626\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -0.330, prior: 0.029, uct:0.6460481338695557, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0  -1  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456627\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.07025986696992602\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.492, prior: 0.030, uct:0.64208036596398, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-3  -1   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456813\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.06192776560783386\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.433, prior: 0.029, uct:0.6329452620060165, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2  -1 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456343\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.06027289728323618\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -0.362, prior: 0.029, uct:0.6470129938117473, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456762\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.09422523062676191\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 8, val: -0.754, prior: 0.029, uct:0.6384401614102693, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456353\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.08229134125368935\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: -0.576, prior: 0.030, uct:0.6477283141552395, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456795\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.018021604667107265\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -0.108, prior: 0.030, uct:0.6313037937653085, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456816\n",
            "  ------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    'C': 2,\n",
        "    'num_searches': 200,\n",
        "    'num_iterations': 1,\n",
        "    'num_selfPlay_iterations': 64,\n",
        "    'num_parallel_games':64,\n",
        "    'num_epochs': 5,\n",
        "    'batch_size': 1024,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.001,\n",
        "}\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "alphaZero = AlphaZero(model, optimizer, bg, args)\n",
        "action_probs, root = alphaZero.mcts.search(INIT_BOARD, [1,3])\n",
        "\n",
        "print(root)\n",
        "for child in sorted(root.children, key=lambda x: (child.value_sum/child.visit_count), reverse=True):\n",
        "    if child.visit_count > 0:\n",
        "        print(f\"avg_value = {child.value_sum/child.visit_count}\")\n",
        "    print(child)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3KYo1hdqZmR"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), f\"/content/gdrive/My\\ Drive/model_final.pt\")\n",
        "# torch.save(optimizer.state_dict(), f\"/content/gdrive/My\\ Drive/optimizer_final.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2d2785b70294e6f91c23462077b16c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AZF.selfPlay(): SP iteration time: 29.1642 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.2692 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.2430 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.6067 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.2859 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.6754 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.0656 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.0275 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.5095 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.8991 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.9479 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.0146 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 37.0398 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.0350 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.0724 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.9746 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.6038 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.2545 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.0643 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.0207 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.2016 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.1544 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.8172 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.1697 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.0784 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.4113 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.3721 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.0562 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.2829 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.4484 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.7868 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.9276 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.2659 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.7574 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 27.8540 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.5052 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.7852 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.6228 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.6639 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.2268 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.1941 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.8834 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 27.4195 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.2442 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.4391 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.2305 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.2009 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.5160 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.8657 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.4710 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.3384 seconds for 62 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.3429 seconds for 61 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.9562 seconds for 61 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.9563 seconds for 61 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 27.2321 seconds for 60 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.9399 seconds for 58 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.8985 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.3155 seconds for 55 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.1053 seconds for 55 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 23.9884 seconds for 55 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 24.3970 seconds for 54 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 23.3242 seconds for 54 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 23.5704 seconds for 53 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 23.5375 seconds for 50 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 21.7281 seconds for 49 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.9066 seconds for 48 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 21.5991 seconds for 48 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.4023 seconds for 48 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 21.0245 seconds for 47 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.0203 seconds for 47 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.6444 seconds for 46 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 16.8780 seconds for 43 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.1378 seconds for 43 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.9052 seconds for 43 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.7493 seconds for 42 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.2885 seconds for 42 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.1837 seconds for 40 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.5715 seconds for 39 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.5831 seconds for 39 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.3419 seconds for 39 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.2569 seconds for 38 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.6361 seconds for 37 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.1829 seconds for 36 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 16.3701 seconds for 34 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.8709 seconds for 34 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.2959 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.8450 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.0828 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 13.3536 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 16.0910 seconds for 31 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.4920 seconds for 31 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.3255 seconds for 31 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.8751 seconds for 31 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.4369 seconds for 31 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.5652 seconds for 28 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.9491 seconds for 27 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.9854 seconds for 27 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 10.8196 seconds for 26 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 10.2932 seconds for 24 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 10.0785 seconds for 23 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 8.6006 seconds for 23 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 10.4775 seconds for 23 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 8.3665 seconds for 21 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.0482 seconds for 20 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.2058 seconds for 20 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.0636 seconds for 19 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.4096 seconds for 18 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.6728 seconds for 17 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.6330 seconds for 16 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.3542 seconds for 14 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.1884 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.0678 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.2439 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.9908 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.2603 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.5255 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.9780 seconds for 11 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.9433 seconds for 11 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.8922 seconds for 11 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.7273 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.1724 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.4456 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.4470 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.2056 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.5342 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.7561 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.9865 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.2727 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.9534 seconds for 9 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.9932 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.0481 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.3569 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.7707 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.3654 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.9489 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.6390 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.7548 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.0806 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.8543 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.5380 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.2872 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.9573 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.9149 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.2387 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.0773 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.5875 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.9154 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.7402 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.7931 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.6007 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1347 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.8429 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.7409 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.6001 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.6035 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.0798 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.0421 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8983 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1415 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.0271 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8578 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8832 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1461 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8644 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.7096 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8658 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.9826 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1524 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8609 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.8031 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.4093 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.6971 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.7026 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5094 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.6811 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5658 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5815 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.0287 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.7596 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.4869 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.6410 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5475 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3088 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3027 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3275 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.2827 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3104 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3075 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.3240 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.2281 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.1440 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 0.3260 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 0.0665 seconds for 0 games with 100 num_searches\n",
            "AFZ.selfPlay(): P1 wins 30 P-1 wins 34\n",
            "AZF.selfPlay(): SP iteration time: 28.6049 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.0854 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.5620 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.2315 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.6684 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.5768 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.3384 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.0954 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.7863 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.2180 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 37.0913 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.4165 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.9136 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.6634 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.6586 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.5075 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.6263 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.2588 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.3012 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.3957 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.3033 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.1101 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.1674 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 35.5116 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 36.5043 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.6549 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 34.1565 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 33.5132 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.9367 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.6514 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.7377 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 32.1106 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.1901 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.6758 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.5546 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.3484 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.9767 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.7563 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.5275 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.6580 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.4936 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.2008 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.1572 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.5248 seconds for 64 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 31.7371 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.9651 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 30.9658 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 29.2900 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.4218 seconds for 63 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.8848 seconds for 62 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 28.4265 seconds for 62 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.2259 seconds for 61 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 27.3267 seconds for 60 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.7663 seconds for 58 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 27.4273 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.9726 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.1051 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.1482 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 26.3513 seconds for 57 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.4622 seconds for 56 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 25.8651 seconds for 56 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 24.3672 seconds for 55 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 23.8555 seconds for 54 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.1041 seconds for 54 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.1792 seconds for 54 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 20.7257 seconds for 53 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 20.7194 seconds for 48 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.3211 seconds for 47 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 20.6209 seconds for 47 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.8404 seconds for 47 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 22.0584 seconds for 44 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.4696 seconds for 44 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.4534 seconds for 44 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.0116 seconds for 42 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.3717 seconds for 42 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.8862 seconds for 40 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.7552 seconds for 39 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 17.1418 seconds for 39 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.6337 seconds for 38 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 19.0228 seconds for 38 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.1773 seconds for 37 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 18.1084 seconds for 36 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.4634 seconds for 36 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.9260 seconds for 36 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.4354 seconds for 35 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.7509 seconds for 34 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.3810 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.1396 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.1830 seconds for 33 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 13.6194 seconds for 30 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 15.0354 seconds for 29 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 14.4151 seconds for 28 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.4035 seconds for 26 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.6652 seconds for 26 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.9126 seconds for 25 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.3578 seconds for 25 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 12.0954 seconds for 25 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 10.0949 seconds for 25 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.6924 seconds for 25 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.2274 seconds for 23 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.9846 seconds for 22 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.9808 seconds for 19 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 11.5007 seconds for 19 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 8.2106 seconds for 17 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.3395 seconds for 17 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 8.4557 seconds for 16 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 8.9128 seconds for 16 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.8891 seconds for 15 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 9.4317 seconds for 15 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.7292 seconds for 15 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 7.7178 seconds for 14 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.6836 seconds for 14 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 6.8773 seconds for 14 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 6.2556 seconds for 14 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 6.7760 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.7763 seconds for 13 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 6.7551 seconds for 12 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.9841 seconds for 12 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.0711 seconds for 11 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.8769 seconds for 11 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 6.4475 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.7167 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.7710 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.0773 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.8059 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.8930 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.3636 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.8808 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.5882 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.9730 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.5158 seconds for 10 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.4418 seconds for 9 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.1597 seconds for 9 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.4906 seconds for 9 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.2944 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.0116 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.4726 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.0009 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.8087 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.6752 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.5134 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.2818 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.6476 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.2189 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.2664 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.1062 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.6826 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.1434 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.8899 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.0531 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.1547 seconds for 8 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.6994 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 5.2727 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.8636 seconds for 7 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.4194 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.3280 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.8524 seconds for 6 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.4262 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 4.3120 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.6015 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.4638 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.3594 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 3.5438 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.8604 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.7929 seconds for 5 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1989 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.8739 seconds for 4 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.0298 seconds for 3 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.7262 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5180 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 2.1090 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.5322 seconds for 2 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 1.0746 seconds for 1 games with 100 num_searches\n",
            "AZF.selfPlay(): SP iteration time: 0.0665 seconds for 0 games with 100 num_searches\n",
            "AFZ.selfPlay(): P1 wins 31 P-1 wins 33\n",
            "AZ.Learn(): Total memory length: 12053\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1998520bd3384b438d1bfc9d5de6ba5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AZ.Train(): Total policy loss: 0.00816875962729198, Total value loss: 0.0008284165623236877\n",
            "AZ.Train(): Total policy loss: 0.006780055729786826, Total value loss: 0.0006364574919377562\n",
            "AZ.Train(): Total policy loss: 0.005827723900074881, Total value loss: 0.00048435059739456804\n",
            "AZ.Train(): Total policy loss: 0.005340210780022917, Total value loss: 0.0003536576123135936\n",
            "AZ.Train(): Total policy loss: 0.005073262835541949, Total value loss: 0.00024844560545628013\n"
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    'C': 2,\n",
        "    'num_searches': 100,\n",
        "    'num_iterations': 1,\n",
        "    'num_selfPlay_iterations': 128,\n",
        "    'num_parallel_games':64,\n",
        "    'num_epochs': 5,\n",
        "    'batch_size': 1024,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.001,\n",
        "}\n",
        "alphaZeroParallel = AlphaZeroParallel(model, optimizer, bg, args)\n",
        "\n",
        "alphaZeroParallel.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = {\n",
        "    'C': 2,\n",
        "    'num_searches': 1000,\n",
        "    'num_iterations': 1,\n",
        "    'num_selfPlay_iterations': 128,\n",
        "    'num_parallel_games':64,\n",
        "    'num_epochs': 3,\n",
        "    'batch_size': 128,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.01,\n",
        "}\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "alphaZero = AlphaZero(model, optimizer, bg, args)\n",
        "action_probs, root = alphaZero.mcts.search(INIT_BOARD, [1,3])\n",
        "\n",
        "# for child in sorted(root.children, key=lambda x: (x.prior) , reverse=True):#/x.visit_count)):\n",
        "#     print(child)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Level: 0, N: 1001, val: 214.528, prior: 0.000, uct:None, weight: 2, num_children: 19\n",
            "   12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "=========================================================\n",
            "|| 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "\n",
            "\n",
            "||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "=========================================================\n",
            "   13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "jumps=[1, 3], state_value=-0.016226641833782196, action_taken=None\n",
            "board = [ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.11954281895199835\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 83, val: -9.922, prior: 0.144, uct:0.6682293799192851, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456761\n",
            "    board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.2865210823584664\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 324, val: -92.833, prior: 0.133, uct:0.6690769271986713, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456345\n",
            "    board = [ 0  2  0  0  0 -1 -4  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0 -1  0  0 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.16829044472251553\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 32, val: 5.385, prior: 0.130, uct:0.6643743918270125, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456816\n",
            "    board = [ 0  2 -1  0  0  0 -4  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.010949946262619713\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 33, val: 0.361, prior: 0.091, uct:0.6639298927855989, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456613\n",
            "    board = [ 0  2  0  0  0  0 -5  0 -3  0 -1  0  5 -4  0  0  0  3  0  5  0  0  0 -1 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.09728692120944078\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 26, val: 2.529, prior: 0.091, uct:0.6641727905419321, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456795\n",
            "    board = [ 0  2  0 -1  0  0 -4  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0 -1 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.22579900036224082\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 79, val: -17.838, prior: 0.070, uct:0.6680285979368867, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456743\n",
            "    board = [ 0  2  0  0  0 -1 -5  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0 -1 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.1858758362631003\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 15, val: 2.788, prior: 0.064, uct:0.6606580971459133, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0  -1   0 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456327\n",
            "    board = [ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0 -1  0 -1  0  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.19891415879714722\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 51, val: -10.145, prior: 0.058, uct:0.6699350958659199, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -2  -1 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456629\n",
            "    board = [ 0  2  0  0  0  0 -5 -1 -2  0 -1  0  5 -4  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.22003933548441398\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 46, val: -10.122, prior: 0.041, uct:0.6654041112064936, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -1  -1 |-5  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456759\n",
            "    board = [ 0  2  0  0  0 -1 -5 -1 -1  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.13742918959435294\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 17, val: -2.336, prior: 0.028, uct:0.6662081687874023, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456785\n",
            "    board = [ 0  2  0  0 -1  0 -5  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.1089243868795725\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 13, val: -1.416, prior: 0.025, uct:0.6691757133244117, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-5   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456762\n",
            "    board = [ 0  2  0  0 -1  0 -5  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.18353266513440758\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 16, val: -2.937, prior: 0.021, uct:0.6687286106896764, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-3  -1   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456813\n",
            "    board = [ 0  2  0 -1  0 -1 -3  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.34281426668167114\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 3, val: 1.028, prior: 0.020, uct:0.6514173736583356, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456353\n",
            "    board = [ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5 -1  0  0  0 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.13808880737051368\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 5, val: 0.690, prior: 0.019, uct:0.6349123632694715, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2  -1 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456343\n",
            "    board = [ 0  2  0  0  0  0 -5 -1 -2  0  0  0  5 -5  0  0  0  3  0  5  0 -1  0  0 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.32914363950137693\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 232, val: -76.361, prior: 0.019, uct:0.6697909364188174, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0  -1  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456627\n",
            "    board = [ 0  2  0  0  0  0 -5  0 -3 -1  0  0  5 -4  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.33193350831667584\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 3, val: 0.996, prior: 0.018, uct:0.6263821138806747, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456330\n",
            "    board = [ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5 -1  0  0  0 -1  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.21835999439160028\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 15, val: -3.275, prior: 0.015, uct:0.6688688873975897, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0  -1   0  -3   0 |-4  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-4   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456631\n",
            "    board = [ 0  2  0  0  0 -1 -4  0 -3  0 -1  0  5 -4  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.27679213881492615\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 1, val: 0.277, prior: 0.007, uct:0.5988102857371297, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -3   0 |-4   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456839\n",
            "    board = [ 0  2 -1  0  0  0 -4  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.23304893573125204\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 6, val: -1.398, prior: 0.005, uct:0.6643067925708592, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2  -1 |-4   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456811\n",
            "    board = [ 0  2  0 -1  0  0 -4 -1 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(root)\n",
        "for child in sorted(root.children, key=lambda x: (x.prior), reverse=True):\n",
        "    if child.visit_count > 0:\n",
        "        print(f\"avg_value = {child.value_sum/child.visit_count}{child}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Level: 0, N: 1001, val: 3.228, prior: 0.000, uct:None, weight: 2, num_children: 19\n",
            "   12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "=========================================================\n",
            "|| 5   0   0   0  -3   0 |-5   0   0   0   0   2 ||  0 \n",
            "\n",
            "\n",
            "||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "=========================================================\n",
            "   13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "jumps=[1, 3], state_value=0.07290183752775192, action_taken=None\n",
            "board = [ 0  2  0  0  0  0 -5  0 -3  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 100, val: -0.087, prior: 0.102, uct:0.5643172322610804, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456761\n",
            "    board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.04452981799840927\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 2, val: 0.089, prior: 1.000, uct:7.144401757667462, weight: 1, num_children: 41\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 1, 1, 1], state_value=0.12661020457744598, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.007576750009320676\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 8, val: -0.061, prior: 1.000, uct:2.7260105972268827, weight: 2, num_children: 18\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 2], state_value=0.11305863410234451, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.015723369394739468\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 9, val: -0.142, prior: 1.000, uct:2.50786168469737, weight: 2, num_children: 17\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 3], state_value=0.10641293227672577, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.011131239589303732\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 6, val: -0.067, prior: 1.000, uct:3.362708476937509, weight: 2, num_children: 12\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 4], state_value=0.09654805809259415, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.019682185724377632\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 6, val: -0.118, prior: 1.000, uct:3.366983950005046, weight: 2, num_children: 9\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 5], state_value=0.08908388763666153, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.00020612627267837524\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 5, val: -0.001, prior: 1.000, uct:3.833436396469673, weight: 2, num_children: 10\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[1, 6], state_value=0.08259100466966629, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.1190609484910965\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 1, val: 0.119, prior: 1.000, uct:10.440469525754452, weight: 1, num_children: 58\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[2, 2, 2, 2], state_value=0.1190609484910965, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.008504537917259667\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 9, val: 0.077, prior: 1.000, uct:2.4957477310413703, weight: 2, num_children: 19\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[2, 3], state_value=0.09327687323093414, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.0046429389039985836\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 8, val: -0.037, prior: 1.000, uct:2.7245436916742216, weight: 2, num_children: 16\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[2, 4], state_value=0.08413244038820267, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.008975128410384059\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 8, val: -0.072, prior: 1.000, uct:2.7267097864274144, weight: 2, num_children: 9\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[2, 5], state_value=0.07658121734857559, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.010223409427063805\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 7, val: 0.072, prior: 1.000, uct:2.994888295286468, weight: 2, num_children: 16\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[2, 6], state_value=0.0736587792634964, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.1150469109416008\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 1, val: 0.115, prior: 1.000, uct:10.4424765445292, weight: 1, num_children: 73\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[3, 3, 3, 3], state_value=0.1150469109416008, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.026734415175659314\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 7, val: -0.187, prior: 1.000, uct:3.0133672075878297, weight: 2, num_children: 14\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[3, 4], state_value=0.07061516493558884, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.03055991269648075\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 5, val: -0.153, prior: 1.000, uct:3.848613289681574, weight: 2, num_children: 10\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[3, 5], state_value=0.06575038284063339, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.043810863979160786\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 4, val: 0.175, prior: 1.000, uct:4.47809456801042, weight: 2, num_children: 16\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[3, 6], state_value=0.06297187507152557, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.11416401714086533\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 1, val: 0.114, prior: 1.000, uct:10.442917991429567, weight: 1, num_children: 21\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[4, 4, 4, 4], state_value=0.11416401714086533, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.0014631228521466255\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 5, val: -0.007, prior: 1.000, uct:3.8340648947594067, weight: 2, num_children: 7\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[4, 5], state_value=0.054579466581344604, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = -0.014292384187380472\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 3, val: -0.043, prior: 1.000, uct:5.50714619209369, weight: 2, num_children: 12\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[4, 6], state_value=0.051488641649484634, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 3.0044466257095337e-05\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 4, val: 0.000, prior: 1.000, uct:4.4999849777668715, weight: 1, num_children: 4\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[5, 5, 5, 5], state_value=0.12029530853033066, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "avg_value = 0.03979658707976341\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 1, val: 0.040, prior: 1.000, uct:10.480101706460118, weight: 2, num_children: 8\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[5, 6], state_value=0.03979658707976341, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n",
            "\n",
            "    ------------------------------------------------------------\n",
            "    Level: 2, N: 0, val: 0.000, prior: 1.000, uct:inf, weight: 1, num_children: 0\n",
            "       12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "    =========================================================\n",
            "    || 5   0   0   0  -2   0 |-4  -2   0   0   0   2 ||  0 \n",
            "    \n",
            "    \n",
            "    ||-5   0   0   0   3   0 | 5   0   0   0   0  -2 ||  0 \n",
            "    =========================================================\n",
            "       13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "    jumps=[6, 6, 6, 6], state_value=None, action_taken=456761\n",
            "        board = [ 0  2  0  0  0 -2 -4  0 -2  0  0  0  5 -5  0  0  0  3  0  5  0  0  0  0 -2  0]\n",
            "    ------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(root)\n",
        "print(root.children[0])\n",
        "for child in root.children[0].children:\n",
        "    if child.visit_count > 0:\n",
        "        print(f\"avg_value = {child.value_sum/child.visit_count}\")\n",
        "    print(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value = 0.07290183752775192\n"
          ]
        }
      ],
      "source": [
        "board = np.array([ 0,  2,  0,  0,  0,  0, -5,  0, -3,  0,  0,  0,  5, -5,  0,  0,  0,  3,  0,  5,  0,  0,  0,  0, -2,  0])  \n",
        "\n",
        "model.eval()\n",
        "enc_board, enc_features = bg.get_encoded_state(board, [1,3])\n",
        "_, value = model(torch.tensor(enc_board, device=device).unsqueeze(0), torch.tensor(enc_features, device=device).unsqueeze(0))\n",
        "print(f\"value = {value.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd7ts8ahaCzR",
        "outputId": "69d3611f-cac9-40ea-f36b-f8d2f28f6e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Level: 0, N: 101, val: -9.363, prior: 0.000, uct:None, weight: 2, num_children: 14\n",
            "   12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "=========================================================\n",
            "|| 0   0   0   0  -1   0 |-3   0   0   0   0   2 ||  0 \n",
            "\n",
            "\n",
            "|| 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "=========================================================\n",
            "   13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "jumps=[1, 3], state_value=0.34306830167770386, action_taken=None\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 28, val: -2.103, prior: 0.131, uct:0.6282955757239076, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-3   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0  -1   0  -1   0 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456327\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 5, val: -0.319, prior: 0.026, uct:0.6173552160604715, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-1  -1   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456813\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 5, val: -0.041, prior: 0.034, uct:0.617831443886931, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-2   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456795\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 9, val: 0.010, prior: 0.067, uct:0.6343879209701166, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0   0 |-3   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456762\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 11, val: 0.202, prior: 0.086, uct:0.6341082895726026, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0   0 |-3   0  -1   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456785\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 15, val: 2.764, prior: 0.175, uct:0.6278574139571371, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0   0 |-2  -2   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456761\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 7, val: 1.522, prior: 0.097, uct:0.6347741808313723, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-3   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456330\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 5, val: 1.129, prior: 0.065, uct:0.6063400760867914, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0   0 |-3  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0  -1  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456743\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 3, val: 1.145, prior: 0.057, uct:0.5967261752491684, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-2  -1   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456345\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 3, val: 1.181, prior: 0.060, uct:0.6069744578694624, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-2   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456839\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 2, val: 0.807, prior: 0.047, uct:0.6097887536496209, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-3   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3  -1   0   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456353\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 4, val: 1.669, prior: 0.073, uct:0.5845077702049273, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0  -1 |-3   0   0   0   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0  -1   0   0  -1 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456343\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 2, val: 0.857, prior: 0.045, uct:0.589415508141325, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0  -1   0 |-2   0   0   0  -1   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456816\n",
            "  ------------------------------------------------------------\n",
            "\n",
            "\n",
            "  ------------------------------------------------------------\n",
            "  Level: 1, N: 1, val: 0.540, prior: 0.037, uct:0.6021266517282708, weight: 1, num_children: 21\n",
            "     12  11  10  9   8   7   6   5   4   3   2   1     0 \n",
            "  =========================================================\n",
            "  || 0   0   0   0   0  -1 |-2   0   0  -1   0   2 ||  0 \n",
            "  \n",
            "  \n",
            "  || 0   0   0   0   1   0 | 3   0   0   0   0  -2 ||  0 \n",
            "  =========================================================\n",
            "     13  14  15  16  17  18  19  20  21  22  23  24    25\n",
            "  jumps=[], state_value=None, action_taken=456811\n",
            "  ------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    'C': 2,\n",
        "    'num_searches': 100,\n",
        "    'num_iterations': 1,\n",
        "    'num_selfPlay_iterations': 128,\n",
        "    'num_parallel_games':64,\n",
        "    'num_epochs': 3,\n",
        "    'batch_size': 128,\n",
        "    'temperature': 1.25,\n",
        "    'dirichlet_epsilon': 0.25,\n",
        "    'dirichlet_alpha': 0.01,\n",
        "}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "alphaZero = AlphaZero(model, optimizer, bg, args)\n",
        "action_probs, root = alphaZero.mcts.search(TEST_BOARD, [1,3])\n",
        "\n",
        "print(root)\n",
        "for child in sorted(root.children, key=lambda x: (x.value_sum / x.visit_count)):#/x.visit_count)):\n",
        "    print(child)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09b2be570c914c0296bbcc870eead837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143f6fc0c8df4930a6df1a01252d1e87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6a3d6df8e74527a504c2757cb9b58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9aea9c55c0b4f35ae9209f70572642f",
            "placeholder": "",
            "style": "IPY_MODEL_67a0c24170ee44408b7d471f6d2ba34a",
            "value": "0%"
          }
        },
        "23dd8e7b07d24a0b8b615afe614a93dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b22c813a6f347068cec389707852ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526b7fd6ec2445088388d6e43d75c337": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534f6c0b49b24c07938bc54280a35630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538328f03f264d88b6e47ef181084e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7052845dfc54262a041afc0d302d660",
            "placeholder": "",
            "style": "IPY_MODEL_09b2be570c914c0296bbcc870eead837",
            "value": "0/1[00:00&lt;?,?it/s]"
          }
        },
        "67a0c24170ee44408b7d471f6d2ba34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afc81fc655748d8808d08d0d2c0f7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "724b8068d83c4801b99e9f7d279410b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f2f08dc3af34ccb9e214603773ffccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa9ea5673b7b485b8900efa8859a44c4",
              "IPY_MODEL_e5ceadea580c4b98888be151431023df",
              "IPY_MODEL_538328f03f264d88b6e47ef181084e8e"
            ],
            "layout": "IPY_MODEL_23dd8e7b07d24a0b8b615afe614a93dd"
          }
        },
        "8e0d0d592db74c86af79fbea8b983a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143f6fc0c8df4930a6df1a01252d1e87",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_724b8068d83c4801b99e9f7d279410b8",
            "value": 0
          }
        },
        "a52fc145e682478f9995b792ea46c915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b22c813a6f347068cec389707852ca9",
            "placeholder": "",
            "style": "IPY_MODEL_534f6c0b49b24c07938bc54280a35630",
            "value": "0/2[00:00&lt;?,?it/s]"
          }
        },
        "a5e86c7799a548729bc846fc9199bb0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7052845dfc54262a041afc0d302d660": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9ea5673b7b485b8900efa8859a44c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e86c7799a548729bc846fc9199bb0c",
            "placeholder": "",
            "style": "IPY_MODEL_c0652338b9334885989fd782803cff63",
            "value": "0%"
          }
        },
        "c0652338b9334885989fd782803cff63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80faf5ce35548c8826f9529036288c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58e29ba016c41f9be4e05240b947338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c6a3d6df8e74527a504c2757cb9b58d",
              "IPY_MODEL_8e0d0d592db74c86af79fbea8b983a65",
              "IPY_MODEL_a52fc145e682478f9995b792ea46c915"
            ],
            "layout": "IPY_MODEL_c80faf5ce35548c8826f9529036288c3"
          }
        },
        "e5ceadea580c4b98888be151431023df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526b7fd6ec2445088388d6e43d75c337",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6afc81fc655748d8808d08d0d2c0f7f3",
            "value": 0
          }
        },
        "f9aea9c55c0b4f35ae9209f70572642f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
